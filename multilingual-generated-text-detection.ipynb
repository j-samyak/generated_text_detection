{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7379337,"sourceType":"datasetVersion","datasetId":4288371},{"sourceId":171230099,"sourceType":"kernelVersion"},{"sourceId":172921358,"sourceType":"kernelVersion"}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T11:06:21.042348Z","iopub.execute_input":"2024-04-20T11:06:21.043173Z","iopub.status.idle":"2024-04-20T11:06:22.807550Z","shell.execute_reply.started":"2024-04-20T11:06:21.043137Z","shell.execute_reply":"2024-04-20T11:06:22.806557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW, set_seed\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:07:44.134618Z","iopub.execute_input":"2024-04-20T11:07:44.135495Z","iopub.status.idle":"2024-04-20T11:07:59.294411Z","shell.execute_reply.started":"2024-04-20T11:07:44.135457Z","shell.execute_reply":"2024-04-20T11:07:59.293279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_seed = 0\nset_seed(random_seed)\ntrain_path =  '/kaggle/input/d/dimitris2sot/semeval2024task8/subtaskA_train_multilingual.jsonl'\ntest_path =  '/kaggle/input/d/dimitris2sot/semeval2024task8/subtaskA_dev_multilingual.jsonl'\n\ntrain_df = pd.read_json(train_path, lines=True)\neval_df = pd.read_json(test_path, lines=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:09:37.404555Z","iopub.execute_input":"2024-04-20T11:09:37.405286Z","iopub.status.idle":"2024-04-20T11:09:51.161821Z","shell.execute_reply.started":"2024-04-20T11:09:37.405251Z","shell.execute_reply":"2024-04-20T11:09:51.160756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:09:59.677753Z","iopub.execute_input":"2024-04-20T11:09:59.678142Z","iopub.status.idle":"2024-04-20T11:09:59.737018Z","shell.execute_reply.started":"2024-04-20T11:09:59.678117Z","shell.execute_reply":"2024-04-20T11:09:59.735783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"human\", 1: \"machine\"}\nlabel2id = {\"human\": 0, \"machine\": 1}\nmodel_name = 'xlm-roberta-base'\n# Initialize the tokenizer and model\ntokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\nmodel = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:10:04.515963Z","iopub.execute_input":"2024-04-20T11:10:04.516359Z","iopub.status.idle":"2024-04-20T11:10:14.609417Z","shell.execute_reply.started":"2024-04-20T11:10:04.516330Z","shell.execute_reply":"2024-04-20T11:10:14.608312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, XLMRobertaConfig, AdamW\n\ntokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\nconfig = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\")\n\n# Define the path to your partially trained model\nmodel_path = \"/kaggle/input/mini-updated-code\"\n\n# Load the partially trained model\nmodel = XLMRobertaForSequenceClassification.from_pretrained(model_path, config=config)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:12:42.933223Z","iopub.execute_input":"2024-04-20T11:12:42.933660Z","iopub.status.idle":"2024-04-20T11:12:53.848211Z","shell.execute_reply.started":"2024-04-20T11:12:42.933625Z","shell.execute_reply":"2024-04-20T11:12:53.847252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:31:16.511530Z","iopub.execute_input":"2024-04-20T11:31:16.512497Z","iopub.status.idle":"2024-04-20T11:31:16.841308Z","shell.execute_reply.started":"2024-04-20T11:31:16.512460Z","shell.execute_reply":"2024-04-20T11:31:16.840394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize text data from DataFrame\ntrain_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True)\neval_encodings = tokenizer(eval_df['text'].tolist(), truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:14:28.410818Z","iopub.execute_input":"2024-04-20T11:14:28.411712Z","iopub.status.idle":"2024-04-20T11:27:03.513470Z","shell.execute_reply.started":"2024-04-20T11:14:28.411675Z","shell.execute_reply":"2024-04-20T11:27:03.512578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save train encodings\ntorch.save(train_encodings, os.path.join(\"/kaggle/working/\", \"train_encodings.pt\"))\nprint(\"Train encodings saved successfully.\")\n\n# Save test encodings\ntorch.save(eval_encodings, os.path.join(\"/kaggle/working/\", \"test_encodings.pt\"))\nprint(\"Test encodings saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:27:24.497586Z","iopub.execute_input":"2024-04-20T11:27:24.498325Z","iopub.status.idle":"2024-04-20T11:29:35.779181Z","shell.execute_reply.started":"2024-04-20T11:27:24.498291Z","shell.execute_reply":"2024-04-20T11:29:35.778013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx]).to(device)\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:29:50.950839Z","iopub.execute_input":"2024-04-20T11:29:50.951238Z","iopub.status.idle":"2024-04-20T11:29:50.958493Z","shell.execute_reply.started":"2024-04-20T11:29:50.951207Z","shell.execute_reply":"2024-04-20T11:29:50.957434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training parameters\nbatch_size = 16\nlearning_rate = 2.0e-5\nnum_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:29:57.993230Z","iopub.execute_input":"2024-04-20T11:29:57.993620Z","iopub.status.idle":"2024-04-20T11:29:57.998271Z","shell.execute_reply.started":"2024-04-20T11:29:57.993589Z","shell.execute_reply":"2024-04-20T11:29:57.997155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_encodings, train_df['label'].tolist())\neval_dataset = CustomDataset(eval_encodings, eval_df['label'].tolist())\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:30:05.025026Z","iopub.execute_input":"2024-04-20T11:30:05.025534Z","iopub.status.idle":"2024-04-20T11:30:05.035555Z","shell.execute_reply.started":"2024-04-20T11:30:05.025503Z","shell.execute_reply":"2024-04-20T11:30:05.034361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and loss function\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:30:07.112264Z","iopub.execute_input":"2024-04-20T11:30:07.113042Z","iopub.status.idle":"2024-04-20T11:30:07.129600Z","shell.execute_reply.started":"2024-04-20T11:30:07.113007Z","shell.execute_reply":"2024-04-20T11:30:07.128706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for training\ndef train(model, optimizer, criterion, dataloader, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * input_ids.size(0)\n            \n            # Release GPU memory\n            del input_ids, attention_mask, labels, outputs\n            torch.cuda.empty_cache()\n\n        epoch_loss = running_loss / len(dataloader.dataset)\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n\n        \n# Function for evaluation\ndef evaluate(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids']\n            attention_mask = batch['attention_mask']\n            labels = batch['labels']\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            preds = torch.argmax(outputs.logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Accuracy: {accuracy:.4f}\")\n    return all_preds,all_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:30:09.970211Z","iopub.execute_input":"2024-04-20T11:30:09.970688Z","iopub.status.idle":"2024-04-20T11:30:09.987324Z","shell.execute_reply.started":"2024-04-20T11:30:09.970650Z","shell.execute_reply":"2024-04-20T11:30:09.986252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, output_dir, epoch):\n    checkpoint_dir = os.path.join(output_dir, \"checkpoints\")\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    model_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch}.pt\")\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, model_path)\n    print(f\"Checkpoint saved at {model_path}\")\n# Function for loading the model and optimizer state\ndef load_checkpoint(model, optimizer, checkpoint_path):\n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    print(f\"Checkpoint loaded from {checkpoint_path}. Resuming training from epoch {epoch + 1}.\")\n    return epoch + 1","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:30:13.276813Z","iopub.execute_input":"2024-04-20T11:30:13.277240Z","iopub.status.idle":"2024-04-20T11:30:13.285158Z","shell.execute_reply.started":"2024-04-20T11:30:13.277197Z","shell.execute_reply":"2024-04-20T11:30:13.284107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune the XLM-RoBERTa model\noutput_dir = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:34:22.284978Z","iopub.execute_input":"2024-04-20T11:34:22.285732Z","iopub.status.idle":"2024-04-20T11:34:22.290292Z","shell.execute_reply.started":"2024-04-20T11:34:22.285684Z","shell.execute_reply":"2024-04-20T11:34:22.289191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optionally resume training from a saved checkpoint\ncheckpoint_path = \"/kaggle/working/checkpoints/model_epoch_1.pt\"\nif os.path.exists(checkpoint_path):\n    start_epoch = load_checkpoint(model, optimizer, checkpoint_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_epoch = 1","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:35:07.602435Z","iopub.execute_input":"2024-04-20T11:35:07.603134Z","iopub.status.idle":"2024-04-20T11:35:07.607548Z","shell.execute_reply.started":"2024-04-20T11:35:07.603101Z","shell.execute_reply":"2024-04-20T11:35:07.606490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(start_epoch, num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, optimizer, criterion, train_loader, 1)\n    save_checkpoint(model, optimizer, output_dir, epoch)\n    all_preds,all_labels = evaluate(model, eval_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T11:35:11.000364Z","iopub.execute_input":"2024-04-20T11:35:11.000778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_checkpoint(model,optimizer,output_dir,2)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T16:40:19.031602Z","iopub.execute_input":"2024-04-20T16:40:19.032036Z","iopub.status.idle":"2024-04-20T16:40:26.138872Z","shell.execute_reply.started":"2024-04-20T16:40:19.032001Z","shell.execute_reply":"2024-04-20T16:40:26.137684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds,all_labels = evaluate(model, eval_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T16:40:38.025989Z","iopub.execute_input":"2024-04-20T16:40:38.026681Z","iopub.status.idle":"2024-04-20T16:42:49.650113Z","shell.execute_reply.started":"2024-04-20T16:40:38.026647Z","shell.execute_reply":"2024-04-20T16:42:49.648883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T16:43:44.395187Z","iopub.execute_input":"2024-04-20T16:43:44.395613Z","iopub.status.idle":"2024-04-20T16:43:44.679765Z","shell.execute_reply.started":"2024-04-20T16:43:44.395579Z","shell.execute_reply":"2024-04-20T16:43:44.678668Z"},"trusted":true},"execution_count":null,"outputs":[]}]}